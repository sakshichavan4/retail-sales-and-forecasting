{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d36866f-bb77-4aec-83f1-776410dfac95",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Importing libraries\n",
    "import pandas as pd\n",
    "import matplotlib.pylab as plt\n",
    "from scipy import stats\n",
    "import numpy as np\n",
    "from itertools import combinations, groupby\n",
    "from collections import Counter\n",
    "import statsmodels.api as sm\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from math import sqrt\n",
    "import seaborn as sb\n",
    "import itertools\n",
    "import datetime\n",
    "%matplotlib inline\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38c0967c-527c-40fe-8c09-e4842c4ed480",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load into pandas dataframe\n",
    "try:\n",
    "    df = pd.read_excel(\"Online_retail_Data.xlsx\")\n",
    "    print(\"Loading Dataset Successful\")\n",
    "except:\n",
    "    print(\"Loading Dataset unsuccessful. Please check if file is present in same folder as this program with file name Online_retail_Data.xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "524a1167-7672-4bc3-aa8e-727310924448",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Checking count of rows and columns in dataset\n",
    "rows, columns = df.shape\n",
    "\n",
    "print(\"Row count:\",rows,\"\\nColumn count:\",columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c891ddb-d9f3-439f-8671-05d2fd1366cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Available features with data type are:\\n\")\n",
    "print(df.dtypes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4487e1b4-5fe7-42cd-8d6d-29109e199b52",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Describing features\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f64b2b05-fe5d-4449-a6b4-d34bf25a4d8f",
   "metadata": {},
   "source": [
    "InvoiceNo - Unique number assigned to a shipment for billing purpose\n",
    "\n",
    "StockCode - Helps track the item for inventory\n",
    "\n",
    "Description - Product name\n",
    "\n",
    "Quantity - Amount purchased\n",
    "\n",
    "InvoiceDate - Date and time of purchase\n",
    "\n",
    "UnitPrice - Cost of product\n",
    "\n",
    "CustomerID - Unique id for customer\n",
    "\n",
    "Country - Contry of purchase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d82ea3c1-5ac4-4bda-823d-9d0c64815f02",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Check for null values in our columns\n",
    "print(df.isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e9349b5-3ac7-4481-bdc6-05252986cade",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Removing null valued rows\n",
    "df = df[~((df['CustomerID'].isnull()) | (df['Description'].isnull()))]\n",
    "print(df.isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "283e294d-ea90-4bef-9718-7f84068d53de",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Removing data with quantity value less than 0\n",
    "df = df[~(df['Quantity']<=0)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7bd1b27-e939-48b3-8965-d1003def87f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Removing data with nan Descripton values\n",
    "df = df[~((df['Description'] == 'nan') | (df['Description'] == 'NAN'))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37f062b7-bea7-4c9a-9710-65fee35744a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creating new useful features\n",
    "\n",
    "#Total cost of purchase\n",
    "df['total_cost'] = df['Quantity'] * df['UnitPrice']\n",
    "\n",
    "#Purchase made on hour of day\n",
    "df['hour'] = pd.DatetimeIndex(df['InvoiceDate']).hour\n",
    "df['day_of_week'] = pd.DatetimeIndex(df['InvoiceDate']).dayofweek\n",
    "df['month'] = pd.DatetimeIndex(df['InvoiceDate']).month\n",
    "df['year'] = pd.DatetimeIndex(df['InvoiceDate']).year\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ef57e5a-4c8f-42fe-b24d-feed8afe1745",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Product sales grouped by hour of day\n",
    "\n",
    "check = pd.DataFrame()\n",
    "check['hour'] = df['hour']\n",
    "check['count'] = df['InvoiceNo']\n",
    "\n",
    "display = check.groupby('hour',as_index=False)['count'].count()\n",
    "\n",
    "#Plotting bar chart\n",
    "plt.bar(display['hour'],display['count'])\n",
    "plt.xlabel('Hour of day')\n",
    "plt.ylabel('Count of item sold')\n",
    "plt.xticks(display['hour'])\n",
    "plt.title('Product sales grouped by hour of day')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3985a45c-25ac-4046-bae7-255d7d1fe49c",
   "metadata": {},
   "source": [
    "Looks like highest number of product sales are made in the afternoon 12 p.m. and sales fall after the evening till morning 6 a.m. This may be because people make most purchases in the afternoon when they have free time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13008568-b311-40b4-95e3-af4628cb30f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Product sales grouped by month\n",
    "\n",
    "check['month'] = df['month']\n",
    "\n",
    "display = check.groupby('month',as_index=False)['count'].count()\n",
    "\n",
    "#Plotting bar chart\n",
    "plt.bar(display['month'],display['count'])\n",
    "plt.xlabel('Month')\n",
    "plt.ylabel('Count of item sold')\n",
    "plt.xticks(display['month'])\n",
    "plt.title('Product sales grouped by month(January=1 to December=12)')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d49ceb73-e3c0-4a4b-bf81-7e65c8a13523",
   "metadata": {},
   "source": [
    "As seen above, the highest count of item were sold in the month of November. This may be due to there is some kind of promotional or seasonal sale on the products in month of November."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67937522-4a37-4513-a909-c3b45888670d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Product sales grouped by country\n",
    "\n",
    "check['Country'] = df['Country']\n",
    "\n",
    "display = check.groupby('Country',as_index=False)['count'].count()\n",
    "\n",
    "#Plotting bar chart\n",
    "plt.figure(figsize=(12,10))\n",
    "plt.bar(display['Country'],display['count'])\n",
    "plt.xlabel('Country')\n",
    "plt.ylabel('Count of item sold')\n",
    "plt.xticks(display['Country'], rotation='vertical')\n",
    "plt.title('Product sales grouped by Country')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "917ed3eb-9008-48ec-b032-7529bef88ddf",
   "metadata": {},
   "source": [
    "From above figure we can infer that ABC company is United Kingdom based company or it has biggest market in UK."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72b39091-835e-4887-937c-0090fb7fa91c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Top selling product by average quantity sold\n",
    "\n",
    "check['Description'] = df['Description']\n",
    "check['Quantity'] = df['Quantity']\n",
    "\n",
    "display = check.groupby('Description',as_index=False)['Quantity'].mean()\n",
    "\n",
    "display.sort_values(by=['Quantity'],ascending=False,inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "faf3e210-9413-4b40-9e69-72614f3a8486",
   "metadata": {},
   "outputs": [],
   "source": [
    "display.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9574de45-faea-40ea-909b-8a8ea62dae6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Top selling product by average revenue earned\n",
    "\n",
    "#check['Description'] = df['Description']\n",
    "check['total_cost'] = df['total_cost']\n",
    "\n",
    "display = check.groupby('Description',as_index=False)['total_cost'].mean()\n",
    "\n",
    "display.sort_values(by=['total_cost'],ascending=False,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ffd632d-8b96-4088-b9b2-7dabb749881e",
   "metadata": {},
   "outputs": [],
   "source": [
    "display.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb8480ff-c7dc-4bdb-a1bc-e9655e4e7ad7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Converting dataframe to series to perform analysis\n",
    "orders = df.set_index('InvoiceNo')['StockCode'].rename('item_id')\n",
    "print(orders.head(10))\n",
    "type(orders)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb3d07c2-10b4-4a15-ac27-8b15fb0d4c93",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Lets check out some order statistics\n",
    "print('Dimension:',orders.shape[0],'\\nUnique orders:',len(orders.index.unique()),\n",
    "      '\\nUnique items:',len(orders.value_counts()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "522fffce-91cf-4d21-a757-2142730b44ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Building functions for association rule\n",
    "\n",
    "#Return count for items and item pairs\n",
    "def freq(iterable):\n",
    "    if isinstance(iterable, pd.core.series.Series):\n",
    "        return iterable.value_counts().rename(\"freq\")\n",
    "    else:\n",
    "        # Use a dictionary to count item pairs\n",
    "        counts = Counter()\n",
    "        for pair in iterable:\n",
    "            counts[pair] += 1\n",
    "        return pd.Series(counts).rename(\"freq\")\n",
    "\n",
    "\n",
    "#Return count of unique orders\n",
    "def order_count(order_item):\n",
    "    return len(set(order_item.index))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#To handle big dataset, I am using generator to give item pairs\n",
    "def get_item_pairs(order_item):\n",
    "    order_item = order_item.reset_index().to_numpy()\n",
    "    for order_id, order_object in groupby(order_item, lambda x: x[0]):\n",
    "        item_list = [item[1] for item in order_object]\n",
    "              \n",
    "        for item_pair in combinations(item_list, 2):\n",
    "            yield tuple(item_pair)  # Ensure item_pair is a tuple of strings (StockCode)\n",
    "\n",
    "\n",
    "\n",
    "# Returns frequency and support associated with item\n",
    "def merge_item_stats(item_pairs, item_stats):\n",
    "    return (item_pairs\n",
    "                .merge(item_stats.rename(columns={'freq': 'freqA', 'support': 'supportA'}),\n",
    "                       left_on='item_A', right_index=True)\n",
    "                .merge(item_stats.rename(columns={'freq': 'freqB', 'support': 'supportB'}),\n",
    "                       left_on='item_B', right_index=True))\n",
    "\n",
    "\n",
    "# Returns name associated with item\n",
    "def merge_item_name(rules, item_name):\n",
    "    columns = ['itemA','itemB','freqAB','supportAB','freqA','supportA','freqB','supportB', \n",
    "               'confidenceAtoB','confidenceBtoA','lift']\n",
    "    rules = (rules\n",
    "                .merge(item_name.rename(columns={'item_name': 'itemA'}), left_on='item_A', right_on='item_id')\n",
    "                .merge(item_name.rename(columns={'item_name': 'itemB'}), left_on='item_B', right_on='item_id'))\n",
    "    return rules[columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8358e52f-3151-4f63-9d34-17b601dd096f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Function for trigerring the rule mining\n",
    "\n",
    "def association_rules(order_item, min_support):\n",
    "\n",
    "    print(\"Starting order_item: {:22d}\".format(len(order_item)))\n",
    "\n",
    "\n",
    "    # Calculate item frequency and support\n",
    "    item_stats             = freq(order_item).to_frame(\"freq\")\n",
    "    item_stats['support']  = item_stats['freq'] / order_count(order_item) * 100\n",
    "\n",
    "\n",
    "    # Filter from order_item items below min support \n",
    "    qualifying_items       = item_stats[item_stats['support'] >= min_support].index\n",
    "    order_item             = order_item[order_item.isin(qualifying_items)]\n",
    "\n",
    "    print(\"Items with support >= {}: {:15d}\".format(min_support, len(qualifying_items)))\n",
    "    print(\"Remaining order_item: {:21d}\".format(len(order_item)))\n",
    "\n",
    "\n",
    "    # Filter from order_item orders with less than 2 items\n",
    "    order_size             = freq(order_item.index)\n",
    "    qualifying_orders      = order_size[order_size >= 2].index\n",
    "    order_item             = order_item[order_item.index.isin(qualifying_orders)]\n",
    "\n",
    "    print(\"Remaining orders with 2+ items: {:11d}\".format(len(qualifying_orders)))\n",
    "    print(\"Remaining order_item: {:21d}\".format(len(order_item)))\n",
    "\n",
    "\n",
    "    # Recalculate item frequency and support\n",
    "    item_stats             = freq(order_item).to_frame(\"freq\")\n",
    "    item_stats['support']  = item_stats['freq'] / order_count(order_item) * 100\n",
    "\n",
    "\n",
    "    # Get item pairs generator\n",
    "    item_pair_gen          = get_item_pairs(order_item)\n",
    "\n",
    "\n",
    "    # Calculate item pair frequency and support\n",
    "    item_pairs              = freq(item_pair_gen).to_frame(\"freqAB\")\n",
    "    item_pairs['supportAB'] = item_pairs['freqAB'] / len(qualifying_orders) * 100\n",
    "\n",
    "    print(\"Item pairs: {:31d}\".format(len(item_pairs)))\n",
    "\n",
    "\n",
    "    # Filter from item_pairs those below min support\n",
    "    item_pairs              = item_pairs[item_pairs['supportAB'] >= min_support]\n",
    "\n",
    "    print(\"Item pairs with support >= {}: {:10d}\\n\".format(min_support, len(item_pairs)))\n",
    "\n",
    "\n",
    "    # Create table of association rules and compute relevant metrics\n",
    "    item_pairs = item_pairs.reset_index().rename(columns={'level_0': 'item_A', 'level_1': 'item_B'})\n",
    "    item_pairs = merge_item_stats(item_pairs, item_stats)\n",
    "    \n",
    "    item_pairs['confidenceAtoB'] = item_pairs['supportAB'] / item_pairs['supportA']\n",
    "    item_pairs['confidenceBtoA'] = item_pairs['supportAB'] / item_pairs['supportB']\n",
    "    item_pairs['lift']           = item_pairs['supportAB'] / (item_pairs['supportA'] * item_pairs['supportB'])\n",
    "    \n",
    "    \n",
    "    # Return association rules sorted by lift in descending order\n",
    "    return item_pairs.sort_values('lift', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b3035dc-8401-4ed9-bbb4-8485771eb1a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Running the model\n",
    "rules = association_rules(orders,0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a650d85f-108a-4186-b106-daecb4cb96c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#lets display the results\n",
    "\n",
    "#Replacing item id with item name\n",
    "item_name = pd.DataFrame()\n",
    "item_name['item_id'] = df['StockCode']\n",
    "item_name['item_name'] = df['Description']\n",
    "\n",
    "item_name.drop_duplicates(inplace=True)\n",
    "\n",
    "#replacing item id with item names\n",
    "final_result = merge_item_name(rules,item_name).sort_values('lift',ascending=False)\n",
    "\n",
    "#Filtering results based on lift value\n",
    "final_result = final_result[(final_result['lift'] > 1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87ef0ad8-2417-4e3b-8c2e-6dfde8b686c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Function for getting the results\n",
    "\n",
    "def item_bought_together(key):\n",
    "    return final_result[final_result['itemA']==key].head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "232e2485-a254-4bc7-b0f2-8b96ad6e531b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Change the key that is item name to see items bought together\n",
    "\n",
    "result = item_bought_together('ENVELOPE 50 ROMANTIC IMAGES')\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71c94b4e-492a-4abd-bfde-5c2ef336cd56",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ensure 'InvoiceDate' is in datetime format\n",
    "df['InvoiceDate'] = pd.to_datetime(df['InvoiceDate'])\n",
    "\n",
    "# Adding week column to dataset\n",
    "df['week'] = df['InvoiceDate'].dt.isocalendar().week\n",
    "\n",
    "# Display the first few rows to verify\n",
    "print(df.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55de4f06-7cea-45dc-b8d7-39b59d75bab1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#We will first filter our data to keep only top 10 products\n",
    "\n",
    "#Top selling product by quantity of product sold\n",
    "\n",
    "check['Description'] = df['Description']\n",
    "check['Quantity'] = df['Quantity']\n",
    "check['StockCode'] = df['StockCode']\n",
    "check['week'] = df['week']\n",
    "\n",
    "display = check.groupby(['Description'],as_index=False).agg({'Quantity':sum, 'StockCode':\"count\"})\n",
    "display.sort_values(by=['Quantity'],ascending=False,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ec43435-5979-43a1-8c63-32ae7f31bdb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Top selling product by quantity of product sold and frequency of purchase\n",
    "display.sort_values(by=['StockCode'],ascending=False,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6e75989-b372-4074-aae9-0dc61316d21e",
   "metadata": {},
   "outputs": [],
   "source": [
    "display['Description'].head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b232e2cf-b8e0-41f7-8837-b7af5ae51028",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[(df['Description'] == 'WHITE HANGING HEART T-LIGHT HOLDER') | \n",
    "       (df['Description'] == 'REGENCY CAKESTAND 3 TIER') |\n",
    "       (df['Description'] == 'JUMBO BAG RED RETROSPOT') |\n",
    "       (df['Description'] == 'ASSORTED COLOUR BIRD ORNAMENT') |\n",
    "       (df['Description'] == 'PARTY BUNTING') |\n",
    "       (df['Description'] == 'LUNCH BAG RED RETROSPOT') |\n",
    "       (df['Description'] == 'SET OF 3 CAKE TINS PANTRY DESIGN ') |\n",
    "       (df['Description'] == 'LUNCH BAG  BLACK SKULL.') |\n",
    "       (df['Description'] == 'POSTAGE') |\n",
    "       (df['Description'] == 'PACK OF 72 RETROSPOT CAKE CASES')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "907127ce-2707-4b7b-b194-d31a51d37a0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#creating new data frame with only required features\n",
    "ts  = pd.DataFrame()\n",
    "ts['Description'] = df['Description']\n",
    "ts['Quantity'] = df['Quantity']\n",
    "ts['InvoiceDate'] = df['InvoiceDate'].dt.date\n",
    "ts['InvoiceDate'] = pd.to_datetime(ts['InvoiceDate'])\n",
    "ts['month'] = df['month']\n",
    "ts['week'] = df['week']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45c697dc-3aef-44e0-a7ef-e20b483d4fc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#For first product\n",
    "#product = 'LUNCH BAG RED RETROSPOT'\n",
    "def building_data(product):\n",
    "    \n",
    "    p1 = pd.DataFrame()\n",
    "    p1['InvoiceDate'] = ts[ts['Description'] == product].InvoiceDate\n",
    "    p1['Quantity'] = ts[ts['Description'] == product].Quantity\n",
    "    p1['month'] = ts[ts['Description'] == product].month\n",
    "    p1['week'] = ts[ts['Description'] == product].week\n",
    "\n",
    "    p1 = p1.groupby('InvoiceDate')['Quantity'].sum().reset_index()\n",
    "\n",
    "\n",
    "    #setting invoice date as index\n",
    "    indexed_p1 = p1.set_index(['InvoiceDate'])\n",
    "\n",
    "    #Resampling our data to weekly frequency and dropping null\n",
    "    y = indexed_p1['Quantity'].resample('W').mean()\n",
    "    y = y.dropna()\n",
    "    \n",
    "    #Checking size for train test split\n",
    "    size = y.shape[0]\n",
    "    \n",
    "    print('data built')\n",
    "    return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4181e5d9-1e36-41a8-988c-52ee9fcb9eec",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_data(product_to_plot):\n",
    "    \n",
    "    #Plotting product quantity sold weekly\n",
    "    product_to_plot.plot(figsize=(15,6))\n",
    "    plt.xlabel(\"Date sampled weekly\")\n",
    "    plt.ylabel(\"Average quantity sold\")\n",
    "    plt.title(\"Quantity of product sold weekly\")\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "    #Performing time-series decomposition to check trend,seasonility and noise\n",
    "\n",
    "    from pylab import rcParams\n",
    "    rcParams['figure.figsize'] = 18,8\n",
    "\n",
    "    decomposition = sm.tsa.seasonal_decompose(product_to_plot, freq=7, model='additive')\n",
    "    fig= decomposition.plot()\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36140b59-56a7-49cd-aac1-6dccf207dee1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sarimax(product_data,size):\n",
    "    # generating parameter combinations\n",
    "    #final_results = []\n",
    "    \n",
    "    #Train and test splitting\n",
    "    train_size = round(size * (80/100))\n",
    "    #print('Train size:',train_size)\n",
    "    test_size = (size - train_size)+1\n",
    "    #print('Test size:',test_size)\n",
    "\n",
    "    train = pd.DataFrame()\n",
    "    test = pd.DataFrame()\n",
    "\n",
    "    train = product_data.head(train_size)\n",
    "    test = product_data.tail(test_size)\n",
    "    \n",
    "\n",
    "    p=d=q=range(0,2)\n",
    "    pdq = list(itertools.product(p,d,q))\n",
    "    seasonal_pdq = [(x[0],x[1],x[2],6)\n",
    "    for x in list(itertools.product(p,d,q))]\n",
    "    # using param combinations to find best RMSE\n",
    "    RMSE_list = pd.DataFrame({}, columns=['param','param_seasonal','RMSE'])\n",
    "    for param in pdq:\n",
    "        for param_seasonal in seasonal_pdq:\n",
    "            try:\n",
    "            #Running the model\n",
    "                mod = sm.tsa.statespace.SARIMAX(train,order=param,seasonal_order = param_seasonal,enforce_stationarity=False,enforce_invertibility=False)\n",
    "                results = mod.fit()\n",
    "                output = results.predict(start=train_size+1,end=train_size+test_size)\n",
    "                #Calculating error for different model parameters\n",
    "                rmse = sqrt(mean_squared_error(test, output))\n",
    "                #print(rmse)\n",
    "                temp = pd.DataFrame([[param,param_seasonal,rmse]], columns=['param','param_seasonal', 'RMSE'])\n",
    "                RMSE_list = RMSE_list.append(temp, ignore_index=True)\n",
    "                del temp\n",
    "            except:\n",
    "                continue\n",
    "    m = np.amin(RMSE_list['RMSE'].values) # finding the lowest error value\n",
    "    l = RMSE_list['RMSE'].tolist().index(m) # extracting the index of lowest error value\n",
    "    minimum_rmse = RMSE_list.iloc[l,:] # Storing the final selected model parameters with lowest RMSE\n",
    "    #print('Lowest rmse:',minimum_rmse)\n",
    "    # Running the model with finalized parameters\n",
    "    print('Predicting weekly quantity required.....\\n')\n",
    "    mod = sm.tsa.statespace.SARIMAX(product_data,order=minimum_rmse['param'],seasonal_order=minimum_rmse['param_seasonal'],enforce_stationarity=False,enforce_invertibility=False)\n",
    "    results = mod.fit()\n",
    "    final_p = results.predict(start=size+1,end=size+12)\n",
    "    final_p[final_p<0] = 0\n",
    "    print(final_p)\n",
    "    print('-------------------------------------------------------------------------------')\n",
    "    return final_p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8a1bf1f-59d0-49dc-9930-6ce915b8e499",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Checking if we only have the data of top 10 products\n",
    "input_list = df['Description'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06f5980a-6cb6-4cc4-a8f7-93e313dbbea6",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in input_list:\n",
    "    print('Performing prediction for: ',i)\n",
    "    prod = building_data(i)\n",
    "    print('Implementing model....')\n",
    "    sarimax(prod,size).head(12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcc7f9cf-dac8-42c6-af71-d5ad135e89c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sarimax(product_data, size):\n",
    "    # Train and test splitting\n",
    "    train_size = round(size * (80 / 100))\n",
    "    test_size = size - train_size + 1\n",
    "\n",
    "    train = product_data.head(train_size)\n",
    "    test = product_data.tail(test_size)\n",
    "\n",
    "    # Generating parameter combinations\n",
    "    p = d = q = range(0, 2)\n",
    "    pdq = list(itertools.product(p, d, q))\n",
    "    seasonal_pdq = [(x[0], x[1], x[2], 6) for x in list(itertools.product(p, d, q))]\n",
    "\n",
    "    # Using parameter combinations to find best RMSE\n",
    "    RMSE_list = pd.DataFrame({}, columns=['param', 'param_seasonal', 'RMSE'])\n",
    "    for param in pdq:\n",
    "        for param_seasonal in seasonal_pdq:\n",
    "            try:\n",
    "                mod = sm.tsa.statespace.SARIMAX(train,\n",
    "                                                order=param,\n",
    "                                                seasonal_order=param_seasonal,\n",
    "                                                enforce_stationarity=False,\n",
    "                                                enforce_invertibility=False)\n",
    "                results = mod.fit()\n",
    "                output = results.predict(start=train_size + 1, end=train_size + test_size)\n",
    "                rmse = sqrt(mean_squared_error(test, output))\n",
    "                temp = pd.DataFrame([[param, param_seasonal, rmse]], columns=['param', 'param_seasonal', 'RMSE'])\n",
    "                RMSE_list = RMSE_list.append(temp, ignore_index=True)\n",
    "                del temp\n",
    "            except:\n",
    "                continue\n",
    "\n",
    "    # Selecting model parameters with lowest RMSE\n",
    "    m = np.amin(RMSE_list['RMSE'].values)\n",
    "    l = RMSE_list['RMSE'].tolist().index(m)\n",
    "    minimum_rmse = RMSE_list.iloc[l, :]\n",
    "\n",
    "    # Running the model with finalized parameters\n",
    "    print('Predicting weekly quantity required.....\\n')\n",
    "    mod = sm.tsa.statespace.SARIMAX(product_data,\n",
    "                                    order=minimum_rmse['param'],\n",
    "                                    seasonal_order=minimum_rmse['param_seasonal'],\n",
    "                                    enforce_stationarity=False,\n",
    "                                    enforce_invertibility=False)\n",
    "    results = mod.fit()\n",
    "    final_p = results.predict(start=size + 1, end=size + 12)\n",
    "    final_p[final_p < 0] = 0\n",
    "    print(final_p)\n",
    "    print('-------------------------------------------------------------------------------')\n",
    "    return final_p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "376fbfef-cde1-4a63-92a7-57ba1d78a56c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Checking if we only have the data of top 10 products\n",
    "input_list = df['Description'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6eee86c9-4ff7-44fc-939e-bd5f1f11cccd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assuming input_list is already defined\n",
    "for product in input_list:\n",
    "    print('Performing prediction for:', product)\n",
    "    product_data = building_data(product)  # Assuming you have a function building_data to get data for each product\n",
    "    print('Implementing model....')\n",
    "    size = len(product_data)  # Determine appropriate size for SARIMAX model\n",
    "    sarimax(product_data, size).head(12)  # Adjust as needed for output and display\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adc3ddf3-c584-488c-a69f-3688fc24aa90",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Get data plotted for specific product, Just key in the value for input_list\n",
    "plot_this = building_data(input_list[1])\n",
    "print('Plotting data for :',input_list[1])\n",
    "plot_data(plot_this)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc7f8434-5336-480d-9039-3ab872acf56e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
